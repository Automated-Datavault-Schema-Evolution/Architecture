@startuml
actor "File System" as FS

FS --> [Filewatcher] : CSV file change detected
[Filewatcher] --> [Kafka Service] : Sends change event
[Kafka Service] --> [Kafka Consumer / PySpark] : Streams data
[Kafka Consumer / PySpark] --> [Datalake Handler] : Sends dataframe

note right of [Datalake Handler]
  Configurable Modes:
  - Real-time streaming & updates
  - Batch-changes (using Kafka streaming)
end note

[Datalake Handler] --> [Postgres/Parquet Storage] : Stores data (config dependent)
[Postgres/Parquet Storage] --> [Data Vault] : Ingest data
[Data Vault] --> [Presentation Layer] : Provide star schema view

' Schema Evolution Framework integration for schema evolution
[Filewatcher] --> [Schema Evolution Framework] : Detects schema evolution
[Schema Evolution Framework] --> [Datalake Handler] : Update data lake schema
[Schema Evolution Framework] --> [Data Vault] : Update vault schema
[Schema Evolution Framework] --> [Presentation Layer] : Update presentation objects
@enduml
